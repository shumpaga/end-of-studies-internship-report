\chapter{Introduction}
\label{ch:introduction}

The need of 3D realistic models is increasingly present in several fields such as architecture, digital simulation or civil and structural engineering. One way to obtain a 3D model might be to build it by hand using specialized modeling softwares. In this case, the realistic aspect of the model could be doubtful. A more reliable way is to use \emph{photogrammetry} or \emph{surface reconstruction} or both at the same time.
\CC is a reality modeling software that can produce highly detailed 3D  models. It creates models of all types or scales from simple photographs of a scene to point clouds or both of them thanks to its hybrid processing. The usage of point clouds gained wide popularity because of the emergence of devices such as optical laser-based range scanners, structured light scanners, LiDAR scanners, Microsoft Kinect, etc. It is only in the past two years that \CC has started to support point clouds.\\
A scanner, whether static or mobile, outputs a point cloud. Given a point cloud $P$ assuming to lie near an unknown shape $S$, the general problem being solved is to construct a digital representation $D$ approximating $S$. A critical step during the construction of $D$ is usually the estimation and orientation of the normal of each point $p \in P$. In order to orient normals and  reconstruct point clouds acquired from static LiDAR scanners, possibly multi-scan\footnote{Point cloud made of several laser scans}, \CC needs to know the position of each scanner in the scene, on the one hand, and the attribution of each point to a scanner on the other. The scanners locations information are not always present in the metadata of some file formats, for instance LAS file format does not even provide it. Detecting the positions of multiple scanners exclusively from a point cloud is a subject neither tackled by academics nor the industry. The scanner position information is lost only due to an export with no metadata. Thus, academic research has not identified this subject as interesting. Itâ€™s only recently that scanner position information is relevant, for a few applications like \CC. The industry did not need an algorithm to retrieve the scanner position up to now and this is the main contribution presented in this internship report: a method able to detect automatically multiple scanners in a single point cloud without prior knowledge of the scene.\\
Knowing scanners position is one thing, orient normals is another. To do so, \CC needs to know for each point which scanner best sees it, there is no need to know exactly which scanner generated it. This enters into the realm of visibility of point clouds. One way to retrieve visibility of point clouds is, firstly, to reconstruct the surface and then use the underlying mesh to compute visibility. But to reconstruct the surface we need to orient the normals, there is a bit of a
chicken-and-egg problem. In \emph{Direct visibility of point sets}~\cite{vis1}, a simple algorithm that computes visibility without reconstructing the surface is introduced: the Hidden Point Removal (HPR) operator. But this operator is not robust to noise which happens quite often in LiDAR point clouds. Some improvements have been proposed in \cite{vis2} but are not good enough to handle LiDAR point clouds noise. Actually, both papers show results obtained on point clouds
describing small closed surfaces such as the statue of David~\cite{david} or the Stanford bunny~\cite{bunny}. Moreover, our purpose here is not to find which points are visible from a precise viewpoint. Different scanners can see the same points and we want to know which scanner best sees it in order to have an accurate normal orientation. We introduce in this internship report a custom point cloud visibility method that serves our purpose and works well with LiDAR point clouds,
regardless of the sampling density.\\
Finally, the last subject covered during this internship is point cloud compression. Reconstructing a surface requires effective machines. The more the scene to reconstruct is bigger, the more the reconstruction can last longer. \CC provides a cloud service which gives the opportunity for people not having any clusters or high-performance machine to do the job. The problem is that, point clouds can be very huge, up to one hundred (100) gibabyte and more. And if something
happens while uploading, the upload restarts from scratch. Point cloud compression can be adressed in two ways: geometric compression~\cite{compress1, compress2} or pure arithmetic compression regardless of the kind of file being compressed. We present... FIXME ...\\

This report is organised as follows. Chapter~\ref{ch:company} present Bentley Systems, Acute3D, \CC and how the achieved work is positioned in the company's business line. After introducing in Chapter~\ref{ch:background} some useful definitions for a better understanding of the report, we describe the achieved work of Scan Finder, Point Cloud Visibility and Point Cloud Compression respectively in Chapter~\ref{ch:scanfinder}, Chapter~\ref{ch:visibility} and
Chapter~\ref{ch:compression}. Note that in each chapter, we recall the context, the issue addressed and the expected result before going into details. Finally Chapter~\ref{ch:conclusion} summarizes all the work, evaluates my contributions to \CC and assess what this experience has brought to me.
