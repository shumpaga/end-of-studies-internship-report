\chapter{Point Cloud Visibility}
\label{ch:visibility}
This chapter introduces our custom point cloud visibility algorithm. It starts by giving in Section~\ref{sc:spec-visibility}, a clear context for the presented work. Then, Section~\ref{sc:related-visibility} gives an overview of the previous related work and describes some experimentations of a previously-published point cloud visibility algorithm. Finally, as nothing seems to be well adjusted for our specific case we implemented a custom point cloud visibility algorithm described in Section~\ref{sc:custom}.

\section{Specifications}
\label{sc:spec-visibility}

\subsection{Context}
Currently in \CC, there is a way to still use a point cloud for reconstructing purposes even if the scanner's location information is lost. It gives the user the opportunity to manually set the scanners position on a 3D representation of the point cloud. But, only one position can be set. It requires that the point cloud contains points resulting from \emph{one and only one} scanner\footnote{Also known as monoscan point cloud.}. This is because, during the reconstruction, \CC uses
the scanner location to orient the normals at each point. In a monoscan point cloud case, it simply orients each normal toward the scanner. But in case of multiscan point cloud, it needs to know for each point, toward which scanner the normal must be oriented, which is less simple to find.

Therefore, even if \emph{ScanFinder} (Chapter~\ref{ch:scanfinder}) is applied on a LAS format\footnote{A point cloud format that \CC wants to support and which does not store scanner locations in its metadata.} multiscan point cloud in order to retrieve all scanner positions, the reconstruction is still infeasible for \CC. This is where a point cloud visibility algorithm is useful in order to attribute each point to a scanner. Have in mind that a point can be seen by two scanners, especially if there is no physical barrier between them. In this case it is difficult to exactly know which scanner produced the point. But, as this point-scanner attribution is only required for normal orientations, we only need to know which scanner best sees it.

\subsection{Objective}
As a final step toward supporting point clouds without scanner locations, the algorithm must:
\begin{itemize}
\item take as input any 3D point cloud captured from static scanners as well as the location of all scanners,
\item be invariant to differences between scanners, such as: density, noise, rotation angle,
\item find for each point the scanner which best sees it, not necessary the scanner which produced it,
\item have a reasonnable running time.
\end{itemize}

As for \emph{ScanFinder} described in Chapter~\ref{ch:scanfinder}, the algorithm is not expected to work with mobile point clouds.


\section{Related work}
\label{sc:related-visibility}
This section highlight some previous work on the subject of \emph{Point cloud visibility} before describing in detail one approach that we tried and the results obtained.

\subsection{Previous work}
Visibility in point clouds is a sucessful topic that experienced several publications since the 1960s~\cite{appel, sutherland, funkhouser, greene, bittner}.

\subsection{An interesting approach: Visibility of Noisy Point Cloud Data}
\label{subsc:noisy}

\subsubsection{Intuition}

\subsubsection{The algorithm}

\subsubsection{Results and discussions}


\section{A custom disk-based approach}
\label{sc:custom}

\subsection{Overview}


\subsection{Implementation}


\subsection{Results and discussions}
